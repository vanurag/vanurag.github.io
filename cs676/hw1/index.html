<html>
<head>
<style type = "text/css">
body
{
	margin-left:50px;
	margin-right:30px;
}

img
{
	margin-left:10px;
	margin-right:10px;
	margin-top:10px;
	margin-bottom:5px;
}

</style>
</head>
<body bgcolor="#E6E6FA">

<h1><center>HomeWork I: Clustering and Image Averaging</center></h1>
<h2><center>Vempati Anurag Sai<br />Y9645<br /></center></h2>

<h3><a href="Y9645_hw1.zip">Y9645_hw1.zip</a></h3>

<h3>PART 0: <i>K-means clustering -</i></h3>

<p><font size="3" font face="georgia">

<p>K-means clustering on randomly generated points in 4 different quadrants. Initial cluster centriods randomly chosen from the data points so that no cluster ends up empty.</p>

<center>
<a href="part0/random_points.jpg"><img src="part0/random_points.jpg" width="300" border="1"/></a></center>
<font size="2"><center>Randomly generated points </center></font>
<font size="1"><center><strong>[Click on the image for expanded view]</strong></center></font>

<p>There is a possibility of having different ways of clustering the data since the initialization is random. Two different ways of clustering are shown in the following figures.</p>
<center>
<a href="part0/K_4(1).jpg"><img src="part0/K_4(1).jpg" width="300" border="1"/> </a>
<a href="part0/K_4(2).jpg"><img src="part0/K_4(2).jpg" width="300" border="1"/> </a>
</center>
<font size="2"><center>Two different ways of clustering observed for k=4</center></font>
<font size="1"><center><strong>[Click for expanded view]</strong></center></font>

<p>In general we don't have an idea of the number of clusters the data has to be grouped into (higer dimensional data, which can't be visualized). We might end up grouping portions of different clusters (smaller 'k') or break a cluter into smaller parts (larger 'k').</p>
<center>
<a href="part0/K_3.jpg"><img src="part0/K_3.jpg" width="300" border="1"/> </a>
<a href="part0/K_5.jpg"><img src="part0/K_5.jpg" width="300" border="1"/> </a>
</center>
<center><pre>k = 3	      <font size="3">[Click for expanded view]</font>	      k = 5</pre></center>

</p>


<h3>PART A: <i>Image smoothing -</i></h3>

<p><font size="3" font face="georgia">

<table align="center">
<tr>
	<td></td>
	<th>T = 150</th>
	<th><font size="2"><center>[Click for expanded view]</center></font><br />T = 850</th>
	<th>T = 1250</th>
</tr>

<tr>
	<th><strong>&#945 = 0</strong></th>
	<td><a href="partA/hw1_0_150.jpg"><img src="partA/hw1_0_150.jpg" width="300"/> </a></td>
	<td><a href="partA/hw1_0_850.jpg"><img src="partA/hw1_0_850.jpg" width="300"/> </a></td>
	<td><a href="partA/hw1_0_1250.jpg"><img src="partA/hw1_0_1250.jpg" width="300"/> </a></td>
</tr>

<tr>
	<th><strong>&#945 = 0.01</strong></th>
	<td><a href="partA/hw1_0.01_150.jpg"><img src="partA/hw1_0.01_150.jpg" width="300"/> </a></td>
	<td><a href="partA/hw1_0.01_850.jpg"><img src="partA/hw1_0.01_850.jpg" width="300"/> </a></td>
	<td><a href="partA/hw1_0.01_1250.jpg"><img src="partA/hw1_0.01_1250.jpg" width="300"/> </a></td>
</tr>

<tr>
	<th><strong>&#945 = 0.1</strong></th>
	<td><a href="partA/hw1_0.1_150.jpg"><img src="partA/hw1_0.1_150.jpg" width="300"/> </a></td>
	<td><a href="partA/hw1_0.1_850.jpg"><img src="partA/hw1_0.1_850.jpg" width="300"/> </a></td>
	<td><a href="partA/hw1_0.1_1250.jpg"><img src="partA/hw1_0.1_1250.jpg" width="300"/> </a></td>
</tr>

<tr>
	<th><strong>&#945 = 1</strong></th>
	<td><a href="partA/hw1_1_150.jpg"><img src="partA/hw1_1_150.jpg" width="300"/> </a></td>
	<td><a href="partA/hw1_1_850.jpg"><img src="partA/hw1_1_850.jpg" width="300"/> </a></td>
	<td><a href="partA/hw1_1_1250.jpg"><img src="partA/hw1_1_1250.jpg" width="300"/> </a></td>
</tr>

</table>

<p>For &#945 = 0 we get the T = 0 frame and for &#945 = 1 we get the final frame. This is evident from the update equation we employ for mean.</p>
<p>For the intermediate values of &#945 we get a blurry image. For &#945 close to 1 the final frame is more evident since it has been given more weightage. For &#945 close to 0 we neglect the new images and the mean is almost time independent.</p>
<p>For the purpose of background subtraction, we build Gaussian model for the intensities of each pixel in the image sequence. We update the mean and &#963 as we keep getting a new image. For the purpose of classification, if the present image's particular pixel intensity differs from it's intensity in the mean image by more than k*&#963 ( '<strong>&#963</strong>' is the standard deviation of the Gaussian model we have built and k is a parameter that has to be tuned) it's considered a foreground pixel and the rest as background.</p>
<p>In the Three Gaussians model, Gaussian model has been built for R, G and B intensities of each pixel. If the present images (R, G, B) tuple lies in an ellipsoidal neighbourhood (whose axes are proportional to <strong>&#963</strong> of that particular colour's Gaussian model) around the mean (R, G, B) tuple, it's considered a background else, a foreground pixel. We might get better results if we use three prominent colours in the spectrum that occur in the image sequence rather than R, G and B to build the model.</p>

<br />
<h3><i>PART A: Background Subtraction -</i></h3>
<br />
<p><strong>Single-Gaussian model:</strong> Each pixel's intensity in the image sequence is modeled using a Gaussian. The image obtained by background subtrction is then eroded (each pixel's intensity replaced by the minimum intensity of the pixels in it's neighbours) and dialated (each pixel's intensity replaced by the minimum intensity of the pixels in it's neighbours) to clean it up. Even voting policy (Each pixel's intensity replaced by the one that occurs more than 60% times in it's neighbourhood. Unchanged, if there isn't one) is employed. The following images show the bacground subtracted image of the t = 150 frame in the PETS2000 sequence.</p> 
<p><strong>Parameters chosen:</strong> &#945 = 0.05 and k = 1 .</p>

<center><a href="partA/Extra/test0150.jpg"><img src="partA/Extra/test0150.jpg" width="300"/> </a></center>
<center>T = 150 frame<font size="1"><center>[Click for expanded view]</center></font><br /></center><br />

<table align="center">

<tr>
	<td><a href="partA/Extra/G_crude.jpg"><img src="partA/Extra/G_crude.jpg" width="300"/> </a></td>
	<td>--Erosion-></td>
	<td><a href="partA/Extra/G_eroded.jpg"><img src="partA/Extra/G_eroded.jpg" width="300"/> </a></td>
	<td>--Dialation-></td>
	<td><a href="partA/Extra/G_dialated.jpg"><img src="partA/Extra/G_dialated.jpg" width="300"/> </a></td>
</tr>

<tr>
	<td><pre>           |<br />           |<br />            ------------- <font size="4">Voting</font> ----></pre></td>
	<td></td>
	<td><a href="partA/Extra/G_voting.jpg"><img src="partA/Extra/G_voting.jpg" width="300"/> </a><font size="2"><center><strong>[Click for expanded view]</strong></center></font></td>
	<td></td>
	<td></td>
</tr>

</table>

<p><strong>Three-Gaussians model:</strong> Each pixel's RGB values in the image sequence are modeled using Gaussians. The image obtained by background subtrction is then eroded and dialated to clean it up. Even voting policy is employed. The following images show the bacground subtracted image of the t = 150 frame in the PETS2000 sequence.</p>
<p><strong>Parameters chosen:</strong> &#945 = 0.05 and k = 15 .</p>

<table align="center">

<tr>
	<td><a href="partA/Extra/3G_crude.jpg"><img src="partA/Extra/3G_crude.jpg" width="300"/> </a></td>
	<td>--Erosion-></td>
	<td><a href="partA/Extra/3G_eroded.jpg"><img src="partA/Extra/3G_eroded.jpg" width="300"/> </a></td>
	<td>--Dialation-></td>
	<td><a href="partA/Extra/3G_dialated.jpg"><img src="partA/Extra/3G_dialated.jpg" width="300"/> </a></td>
</tr>

<tr>
	<td><pre>           |<br />           |<br />            ------------- <font size="4">Voting</font> ----></pre></td>
	<td></td>
	<td><a href="partA/Extra/3G_voting.jpg"><img src="partA/Extra/3G_voting.jpg" width="300"/> </a><font size="2"><center><strong>[Click for expanded view]</strong></center></font></td>
	<td></td>
	<td></td>
</tr>

</table>

<p>As we can see, even the person walking down the path at the top of the image is detected. Voting policy preserves this while erosion wipes it off. Three-Gaussians model has a slight improvement over the Single-Gaussian.</p>

<h3><i>PART B: Colour Level Reduction by K-means -</i></h3>

<center><font size="2"><center>[Click for expanded view]</center></font><a href="partB/test0130.jpg"><img src="partB/test0130.jpg" width="250"/> </a></center>
<center>Actual Image</center><br />

<table align="center">

<tr>
	<td><a href="partB/partB_5.jpg"><img src="partB/partB_5.jpg" width="250"/> </a></td>
	<td><a href="partB/partB_10.jpg"><img src="partB/partB_10.jpg" width="250"/> </a></td>
	<td><a href="partB/partB_20.jpg"><img src="partB/partB_20.jpg" width="250"/> </a></td>
	<td><a href="partB/partB_40.jpg"><img src="partB/partB_40.jpg" width="250"/> </a></td>
</tr>

<tr>
	<td><center>K = 5</center></td>
	<td><center>K = 10</center></td>
	<td><center>K = 20</center></td>
	<td><center>K = 40</center></td>
</tr>

</table>

<p>If the sum of the shifts in cluster centroids from previous iteration is less than some &#949 (just a parameter, chosen as 10. K = 40 took about 2 mins to converge), convergence is assumed. Cluster centroids have been randomly initialized. So, there is a chance of getting different set of '<strong>k</strong>' colours in each run.</p>
<br /><br /><br />
</p>





</body>
</html>