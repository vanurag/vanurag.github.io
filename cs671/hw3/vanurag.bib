@inproceedings{tellex2011understanding,
  title={Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation.},
  author={Tellex, Stefanie and Kollar, Thomas and Dickerson, Steven and Walter, Matthew R and Banerjee, Ashis Gopal and Teller, Seth J and Roy, Nicholas},
  booktitle={AAAI},
  year={2011}
  annote = { The authors propose a new model for understanding natural language commands given to autonomous systems that perform navigation and mobile manipulation in semi-structured environments.Their framework, called Generalized Grounding Graphs (G ), dynamically instantiates a probabilistic graphical model for a particular natural language command according to the commandâ€™s hierarchical and compositional semantic structure. Previous approaches assume that natural language commands have a fixed and flat structure that can be used to infer the likelihood of a sequence of actions given the environment and the command. However, this kind of fixed and flat sequential structure does not allow for variable arguments or nested clauses. For example a sentences like "It wouldn't be fair if we should think that it was his fault when he wasn't even awake" cannot be fit into a fixed and flat structure. In order to infer the meaning of unconstrained natural language commands, this work tries to come up with a model to exploit the compositional and hierarchical linguistic structures at both learning and inference time.
\textbf{Framework:}\\
They introduce a new model called Generalized Grounding Graphs (G3). A grounding graph is a probabilistic graphical model that is instantiated dynamically based on the natural language command. Given a natural language command, the structure of the grounding graph model is induced using Spatial Description Clauses (SDCs). A natural language command is represented as a tree of SDCs. Each SDC essentially represents a linguistic constituent from the command that can be mapped to an aspect of the world or grounding, such as an object, place, path or event. 
An example SDC tree for the sentence "Put the pallet on the truck" would be:\\
EVENT1 (r = Put,\\
	l = OBJ2 (f = the pallet),\\
	l2 = P LACE3(r = on,\\
		l = OBJ4(f = the truck)))\\
Now given a training set of 'actions' paired with their 'natural language description', the problem is framed as an optimization problem of maximizing a conditional probability of, correct mapping among the portions of NL commands and grounded entities conditioned upon the NL command and set of all the grounded entities. Now, the induced grounding graph for a given command is a bipartite factor graph which can be interpreted as a structured CRF, enabling the system to learn over a rich compositional action space. The problem is formulated in such a way as to make it domain-independent learning and inference system.\\
During inference they search for groundings that maximize the probability of a match. Because the space of potential groundings includes all permutations of object assignments, as well as every feasible sequence of actions the agent might perform, the search space becomes large as the number of objects and potential manipulations in the world increases. In order to make the inference tractable, they use a beam search to bound the number of candidate groundings considered for any particular SDC.\\
\textbf{Evaluation:}\\
The corpus consists of commands collected from 45 subjects for 22 different videos showing a forklift executing an action in a simulated warehouse. This proposed method had an accuracy of 86\% and F-Score of 89\% in predicting the mapping between the portions of NL command and grounded entities. The errors mostly were due to less commonly appearing words in the corpus and commands that involved frame of reference like "just to the right of the furthest skid of tires". An end-to-end evaluation was performed by asking various subjects to rate the relevance of a NL command to two different videos on a scale of 5. One video was the action executed by the simulator while the other one is a random action.  The fraction of end-to-end commands considered correct by the subjects for correct video was 91\% as opposed to 11\% for random videos.\\
\textbf{Limitations:}\\
While Unsupervised or semi-supervised modelling frameworks in which the object groundings are latent variables have the potential to exploit much larger corpora this method is limited by the number of available annotations. Another limitation is the size of the search space; more complicated task domains require deeper search and more sophisticated algorithms. Many complex linguistic phenomena such as abstract objects, negation, anaphora, conditionals, and quantifiers are not supported by this system.
\#\#\#\#\#\#\# Vempati Anurag Sai, Y9227645 \#\#\#\#\#\#\#
}
}





